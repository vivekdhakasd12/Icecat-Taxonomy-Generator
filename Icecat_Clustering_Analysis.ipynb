{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Icecat Taxonomy Clustering Analysis\n",
                "\n",
                "This notebook orchestrates the clustering analysis using the modular `src` package.\n",
                "It performs:\n",
                "1.  Data Loading (from JSON)\n",
                "2.  Feature Engineering (Text Embeddings)\n",
                "3.  Clustering (KMeans, HDBSCAN, DBSCAN, Agglomerative)\n",
                "4.  Evaluation (Metrics)\n",
                "5.  Visualization (Interactive 2D Plots)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup & Imports\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from src import config, data_loader, features, clustering, evaluation, visualization\n",
                "Developer: Reload Window\n",
                "print(f\"Using Data Path: {config.DATA_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Load Data\n",
                "try:\n",
                "    df = data_loader.load_icecat_data()\n",
                "    print(f\"Loaded {len(df)} records.\")\n",
                "except FileNotFoundError as e:\n",
                "    print(e)\n",
                "    print(\"Please ensure the dataset path in `src/config.py` is correct.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Feature Engineering\n",
                "if 'df' in locals():\n",
                "    df = features.create_text_features(df)\n",
                "    embeddings = features.generate_embeddings(df)\n",
                "    print(f\"Embeddings shape: {embeddings.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Clustering Experiments\n",
                "results = {}\n",
                "labels_dict = {}\n",
                "\n",
                "if 'embeddings' in locals():\n",
                "    # Prepare Ground Truth if available\n",
                "    y_true = df[config.LABEL_COL] if config.LABEL_COL in df.columns else None\n",
                "    \n",
                "    # --- K-Means ---\n",
                "    labels_km = clustering.run_kmeans(embeddings, n_clusters=50)\n",
                "    metrics_km = evaluation.compute_metrics(embeddings, labels_km, y_true)\n",
                "    results['KMeans'] = metrics_km\n",
                "    labels_dict['KMeans'] = labels_km\n",
                "    print(f\"KMeans Metrics: {metrics_km}\")\n",
                "\n",
                "    # --- HDBSCAN ---\n",
                "    labels_hdb = clustering.run_hdbscan(embeddings)\n",
                "    metrics_hdb = evaluation.compute_metrics(embeddings, labels_hdb, y_true)\n",
                "    results['HDBSCAN'] = metrics_hdb\n",
                "    labels_dict['HDBSCAN'] = labels_hdb\n",
                "    print(f\"HDBSCAN Metrics: {metrics_hdb}\")\n",
                "    \n",
                "    # --- DBSCAN ---\n",
                "    labels_db = clustering.run_dbscan(embeddings, eps=0.5, min_samples=5)\n",
                "    metrics_db = evaluation.compute_metrics(embeddings, labels_db, y_true)\n",
                "    results['DBSCAN'] = metrics_db\n",
                "    labels_dict['DBSCAN'] = labels_db\n",
                "    print(f\"DBSCAN Metrics: {metrics_db}\")\n",
                "    \n",
                "    # --- Agglomerative ---\n",
                "    # (Can be slow for >20k points)\n",
                "    if len(df) <= 20000:\n",
                "        labels_agg = clustering.run_agglomerative(embeddings, n_clusters=50)\n",
                "        metrics_agg = evaluation.compute_metrics(embeddings, labels_agg, y_true)\n",
                "        results['Agglomerative'] = metrics_agg\n",
                "        labels_dict['Agglomerative'] = labels_agg\n",
                "        print(f\"Agglomerative Metrics: {metrics_agg}\")\n",
                "    else:\n",
                "        print(\"Skipping Agglomerative Clustering (dataset too large for O(N^2) memory).\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Comparison Table\n",
                "if results:\n",
                "    df_results = pd.DataFrame(results).T\n",
                "    display(df_results.style.highlight_max(axis=0, color='lightgreen'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Visual Analysis (t-SNE / UMAP)\n",
                "\n",
                "# Choose model to visualize (e.g., HDBSCAN or KMeans)\n",
                "MODEL_TO_PLOT = 'HDBSCAN'\n",
                "\n",
                "if 'embeddings' in locals() and MODEL_TO_PLOT in labels_dict:\n",
                "    # Reduce to 2D (Sample if huge)\n",
                "    if len(embeddings) > 10000:\n",
                "        idx = np.random.choice(len(embeddings), 10000, replace=False)\n",
                "        emb_viz = embeddings[idx]\n",
                "        lab_viz = labels_dict[MODEL_TO_PLOT][idx]\n",
                "        true_viz = y_true.iloc[idx] if y_true is not None else None\n",
                "    else:\n",
                "        emb_viz = embeddings\n",
                "        lab_viz = labels_dict[MODEL_TO_PLOT]\n",
                "        true_viz = y_true\n",
                "\n",
                "    # 1. Compute 2D projection\n",
                "    embeddings_2d = visualization.reduce_dimensions(emb_viz, method='umap') # Try 'umap' or 'tsne' or 'pca'\n",
                "    \n",
                "    # 2. Plot\n",
                "    visualization.plot_clusters_2d(\n",
                "        embeddings_2d, \n",
                "        lab_viz, \n",
                "        title=f\"Cluster Visualization ({MODEL_TO_PLOT})\", \n",
                "        true_labels=true_viz,\n",
                "        interactive=True\n",
                "    )"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
